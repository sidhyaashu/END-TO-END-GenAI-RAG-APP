{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Optional\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.llm import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"gen-ai-rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting to load documents from 'D:\\Gen_AI\\END-TO-END-GenAI-RAG-APP\\data' with pattern '*.pdf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully loaded 2 documents.\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def pdf_loader(path: str, glob_pattern: str = \"*.pdf\", loader_cls=PyMuPDFLoader) -> Optional[List[dict]]:\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Starting to load documents from '{path}' with pattern '{glob_pattern}'\")\n",
    "        \n",
    "        # Check if the directory exists\n",
    "        if not os.path.isdir(path):\n",
    "            logger.error(f\"The directory '{path}' does not exist.\")\n",
    "            return None\n",
    "        \n",
    "        # Load the PDF files\n",
    "        loader = DirectoryLoader(path, glob=glob_pattern, loader_cls=loader_cls)\n",
    "        documents = loader.load()\n",
    "\n",
    "        logger.info(f\"Successfully loaded {len(documents)} documents.\")\n",
    "\n",
    "        return documents\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logger.error(f\"File not found error: {fnf_error}\")\n",
    "    except AttributeError as attr_error:\n",
    "        logger.error(f\"Attribute error: {attr_error}. Check the structure of loaded documents.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while loading PDF: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "extracted_data = pdf_loader(\"D:\\\\Gen_AI\\\\END-TO-END-GenAI-RAG-APP\\\\data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(data):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=120, chunk_overlap=0)\n",
    "    text_chunks = text_splitter.split_documents(data)\n",
    "    \n",
    "    return text_chunks\n",
    "\n",
    "docs = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "d:\\Download\\anaconda_exe\\install\\envs\\genairag\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['d:\\\\Download\\\\anaconda_exe\\\\install\\\\envs\\\\genairag\\\\lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n"
     ]
    }
   ],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "        docs,\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "if The data does not exist in the database then just say data is not present on the database,don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'max_new_tokens': 100, 'repetition_penalty': 1.1}\n",
    "llm = CTransformers(\n",
    "    model=\"../model/llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = llm | PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore_from_docs.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ctransformers:Number of tokens (1052) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1053) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1054) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1055) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1056) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1057) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1058) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1059) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1060) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1061) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1062) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1063) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1064) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1065) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1066) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1067) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1068) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1069) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1070) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1071) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1072) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1073) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1074) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1075) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1076) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1077) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1078) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1079) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1080) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1081) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1082) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1083) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1084) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1085) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1086) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1087) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1088) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1089) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1090) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1091) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1092) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1093) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1094) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1095) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1096) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1097) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1098) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1099) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1100) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1101) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1102) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1103) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1104) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1105) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1106) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1107) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1108) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1109) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1110) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1111) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1112) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1113) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1114) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1115) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1116) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1117) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1118) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1119) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1120) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1121) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1122) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1123) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1124) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1125) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1126) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1127) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1128) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1129) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1130) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1131) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1132) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1133) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1134) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1135) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1136) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1137) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1138) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1139) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1140) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1141) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1142) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1143) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1144) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1145) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1146) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1147) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1148) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1149) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1150) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1151) exceeded maximum context length (512).\n",
      "WARNING:ctransformers:Number of tokens (1152) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is Asutosh Sidhya?', 'result': \" I don's 109 days ago were finalized for Clarify friend sat on the question: I donated their questions about the question at Brain were walking towards fellow students, Asutia Sidhuda discussed their questionThe project on February \\nWhat is here walked back to Questions, but they encountered him with the question: I don's were working in ASutosh sat inquired about A TAsutya walked across from a friend. I don's\"}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the context and query\n",
    "query = \"Who is Asutosh Sidhya?\"\n",
    "\n",
    "# Call the invoke method with the correct input keys\n",
    "result = qa.invoke({\"query\": query})  # Ensure you include context if required\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genairag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
